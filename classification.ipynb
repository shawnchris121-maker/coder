{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd8e1475",
        "outputId": "b98ab580-b8d4-495e-958b-a30b8858e86f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/iris (2).xls')\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataFrame Info (data types and non-null values):\")\n",
        "df.info()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "    SL   SW   PL   PW Classification\n",
            "0  5.1  3.5  1.4  0.2    Iris-setosa\n",
            "1  4.9  3.0  1.4  0.2    Iris-setosa\n",
            "2  NaN  3.2  1.3  0.2    Iris-setosa\n",
            "3  4.6  3.1  1.5  0.2    Iris-setosa\n",
            "4  5.0  3.6  1.4  0.2    Iris-setosa\n",
            "\n",
            "DataFrame Info (data types and non-null values):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   SL              143 non-null    float64\n",
            " 1   SW              144 non-null    float64\n",
            " 2   PL              144 non-null    float64\n",
            " 3   PW              150 non-null    float64\n",
            " 4   Classification  150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7525235b",
        "outputId": "e52dac99-2092-4d33-b978-d007be8cd3b6"
      },
      "source": [
        "print(\"Missing values before imputation:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Impute missing values with the mean of each column\n",
        "for column in ['SL', 'SW', 'PL']:\n",
        "    if df[column].isnull().any():\n",
        "        df[column].fillna(df[column].mean(), inplace=True)\n",
        "\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nFirst 5 rows of the DataFrame after imputation:\")\n",
        "print(df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before imputation:\n",
            "SL                7\n",
            "SW                6\n",
            "PL                6\n",
            "PW                0\n",
            "Classification    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after imputation:\n",
            "SL                0\n",
            "SW                0\n",
            "PL                0\n",
            "PW                0\n",
            "Classification    0\n",
            "dtype: int64\n",
            "\n",
            "First 5 rows of the DataFrame after imputation:\n",
            "         SL   SW   PL   PW Classification\n",
            "0  5.100000  3.5  1.4  0.2    Iris-setosa\n",
            "1  4.900000  3.0  1.4  0.2    Iris-setosa\n",
            "2  5.855944  3.2  1.3  0.2    Iris-setosa\n",
            "3  4.600000  3.1  1.5  0.2    Iris-setosa\n",
            "4  5.000000  3.6  1.4  0.2    Iris-setosa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2160805713.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(df[column].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fe44372",
        "outputId": "85225196-52df-45ef-c1da-dc8e9a6bc0e2"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encode the 'Classification' column\n",
        "le = LabelEncoder()\n",
        "df['Classification_encoded'] = le.fit_transform(df['Classification'])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(['Classification', 'Classification_encoded'], axis=1)\n",
        "y = df['Classification_encoded']\n",
        "\n",
        "print(\"First 5 rows of features (X):\")\n",
        "print(X.head())\n",
        "print(\"\\nFirst 5 rows of target (y):\")\n",
        "print(y.head())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of features (X):\n",
            "         SL   SW   PL   PW\n",
            "0  5.100000  3.5  1.4  0.2\n",
            "1  4.900000  3.0  1.4  0.2\n",
            "2  5.855944  3.2  1.3  0.2\n",
            "3  4.600000  3.1  1.5  0.2\n",
            "4  5.000000  3.6  1.4  0.2\n",
            "\n",
            "First 5 rows of target (y):\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: Classification_encoded, dtype: int64\n",
            "\n",
            "Shape of X_train: (120, 4)\n",
            "Shape of X_test: (30, 4)\n",
            "Shape of y_train: (120,)\n",
            "Shape of y_test: (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052c9853",
        "outputId": "c3296b3c-0408-4d74-fb15-972703dbde1c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=200),\n",
        "    'SVC': SVC(random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Iterate through models, train, and evaluate\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n----- {name} -----\")\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Random Forest -----\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "----- Logistic Regression -----\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "----- SVC -----\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "----- Decision Tree -----\n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}